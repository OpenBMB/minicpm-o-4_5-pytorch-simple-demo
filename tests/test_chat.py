"""ChatView é›†æˆæµ‹è¯•ï¼ˆæ•°æ®é©±åŠ¨ï¼‰

æµ‹è¯• Chat æ¨¡å¼çš„å„ç§è¾“å…¥ç±»å‹ã€‚

**è®¾è®¡åŸåˆ™**ï¼š
- æµ‹è¯•æ•°æ®å­˜æ”¾åœ¨ resources/cases/chat/*.json
- æ¯ä¸ª JSON æ–‡ä»¶åŒ…å« descriptionã€inputã€expected
- æµ‹è¯•ä»£ç åªè´Ÿè´£åŠ è½½æ•°æ®ã€æ‰§è¡Œã€éªŒè¯
- æ— çŠ¶æ€æ¨¡å¼ï¼Œä¸éœ€è¦çŠ¶æ€æµ‹è¯•

è¿è¡Œå‘½ä»¤ï¼š
cd /user/sunweiyue/lib/swy-dev/minicpmo45_service
CUDA_VISIBLE_DEVICES=0 PYTHONPATH=. .venv/base/bin/python -m pytest tests/test_chat.py -v -s
"""

import sys
import base64
from pathlib import Path

import pytest

# æ·»åŠ  tests ç›®å½•åˆ° path
_tests_dir = Path(__file__).parent
if str(_tests_dir) not in sys.path:
    sys.path.insert(0, str(_tests_dir))

from conftest import (
    CaseSaver,
    MODEL_PATH,
    get_cases,
    load_case,
    assert_expected,
)

from core.schemas import (
    ChatRequest,
    Message,
    Role,
    TextContent,
    ImageContent,
    AudioContent,
    TTSConfig,
    TTSMode,
    GenerationConfig,
)
from core.processors import UnifiedProcessor, ChatView


# =============================================================================
# Fixture: å…±äº«çš„ Processor å®ä¾‹ï¼ˆé¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼‰
# =============================================================================

@pytest.fixture(scope="module")
def processor():
    """åˆ›å»ºå…±äº«çš„ ChatView å®ä¾‹"""
    from conftest import PT_PATH
    print(f"\n[Setup] åŠ è½½æ¨¡å‹: {MODEL_PATH}")
    print(f"[Setup] é¢å¤–æƒé‡: {PT_PATH}")
    unified = UnifiedProcessor(model_path=MODEL_PATH, pt_path=PT_PATH)
    chat_view = unified.set_chat_mode()
    yield chat_view
    print("\n[Teardown] é‡Šæ”¾æ¨¡å‹")
    del unified


# =============================================================================
# æ•°æ®æµ‹è¯•ï¼ˆData-Drivenï¼‰
# =============================================================================

class TestChatData:
    """Chat æ•°æ®æµ‹è¯• - æ‰€æœ‰ case å…±ç”¨ä¸€ä¸ªæµ‹è¯•æ–¹æ³•"""
    
    @pytest.mark.parametrize("case_name", get_cases("chat"))
    def test_chat(self, processor, case_saver, case_name: str):
        """æ•°æ®é©±åŠ¨çš„ Chat æµ‹è¯•"""
        saver: CaseSaver = case_saver(case_name, "chat")
        
        # åŠ è½½ case æ•°æ®
        case = load_case("chat", case_name, output_dir=saver.base_dir)
        print(f"\nğŸ“‹ {case['description']}")
        
        # æ„é€ è¯·æ±‚
        request = self._build_request(case["input"], saver)
        
        # ä¿å­˜è¾“å…¥
        saver.save_input(request)
        
        # æ‰§è¡Œæ¨ç†
        response = processor.chat(request)
        
        # ä¿å­˜è¾“å‡º
        saver.save_output(response)
        saver.finalize({"case_name": case_name, "description": case["description"]})
        
        # éªŒè¯
        assert_expected(response, case["expected"], output_dir=saver.base_dir)
        
        # æ‰“å°ç»“æœ
        text = response.text or ""
        print(f"âœ… {case_name}: {text[:80]}{'...' if len(text) > 80 else ''}")
    
    def _build_request(self, input_data: dict, saver: CaseSaver) -> ChatRequest:
        """ä» JSON input æ„é€  ChatRequest"""
        messages = []
        
        for msg_data in input_data.get("messages", []):
            content = msg_data["content"]
            
            # å¤„ç†å¤åˆå†…å®¹ï¼ˆå›¾åƒã€éŸ³é¢‘ï¼‰
            if isinstance(content, list):
                content_items = []
                for item in content:
                    if item["type"] == "text":
                        content_items.append(TextContent(text=item["text"]))
                    elif item["type"] == "image":
                        src_path = Path(item["path"])
                        if src_path.exists():
                            saver.copy_input_file(src_path, src_path.name)
                        img_b64 = base64.b64encode(src_path.read_bytes()).decode()
                        content_items.append(ImageContent(data=img_b64))
                    elif item["type"] == "audio":
                        import librosa, numpy as np
                        src_path = Path(item["path"])
                        if src_path.exists():
                            saver.copy_input_file(src_path, src_path.name)
                        audio, _ = librosa.load(str(src_path), sr=16000, mono=True)
                        audio_b64 = base64.b64encode(audio.astype(np.float32).tobytes()).decode()
                        content_items.append(AudioContent(data=audio_b64))
                content = content_items
            
            messages.append(Message(
                role=Role(msg_data["role"]),
                content=content,
            ))
        
        # æ„é€ ç”Ÿæˆé…ç½®
        generation = None
        if "generation" in input_data:
            generation = GenerationConfig(**input_data["generation"])
        
        # æ„é€  TTS é…ç½®
        tts = None
        if "tts" in input_data:
            tts_data = input_data["tts"]
            # å¤åˆ¶å‚è€ƒéŸ³é¢‘
            if "ref_audio_path" in tts_data:
                ref_path = Path(tts_data["ref_audio_path"])
                if ref_path.exists():
                    saver.copy_input_file(ref_path, "ref_audio.wav")
            tts = TTSConfig(
                enabled=tts_data.get("enabled", True),
                mode=TTSMode(tts_data.get("mode", "audio_assistant")),
                ref_audio_path=tts_data.get("ref_audio_path"),
                output_path=tts_data.get("output_path"),
            )
        
        # åªä¼ æœ‰å€¼çš„å‚æ•°
        kwargs = {"messages": messages}
        if generation is not None:
            kwargs["generation"] = generation
        if tts is not None:
            kwargs["tts"] = tts
        
        return ChatRequest(**kwargs)


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
