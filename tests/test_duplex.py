"""DuplexView é›†æˆæµ‹è¯•ï¼ˆæ•°æ®é©±åŠ¨ + çŠ¶æ€æµ‹è¯•ï¼‰

æµ‹è¯• Duplex æ¨¡å¼çš„åŠŸèƒ½å’ŒçŠ¶æ€ç®¡ç†ã€‚

**è®¾è®¡åŸåˆ™**ï¼š
- æ•°æ®æµ‹è¯•ï¼šresources/cases/duplex/*.json
- ç‰¹æ®Šæ„é€ é€»è¾‘åœ¨æµ‹è¯•å‡†å¤‡é˜¶æ®µå®Œæˆï¼Œç”Ÿæˆæ ‡å‡† DuplexOfflineInput
- input.json / output.json å§‹ç»ˆæ˜¯æ ‡å‡† Schema
- çŠ¶æ€æµ‹è¯•ï¼šéªŒè¯ prepare/prefill/generate æµç¨‹

è¿è¡Œå‘½ä»¤ï¼š
cd /user/sunweiyue/lib/swy-dev/minicpmo45_service
CUDA_VISIBLE_DEVICES=0 PYTHONPATH=. .venv/base/bin/python -m pytest tests/test_duplex.py -v -s
"""

import sys
import time
from pathlib import Path
from typing import List, Optional

import librosa
import numpy as np
import pytest
import soundfile as sf
import torch
from PIL import Image

# æ·»åŠ  tests ç›®å½•åˆ° path
_tests_dir = Path(__file__).parent
if str(_tests_dir) not in sys.path:
    sys.path.insert(0, str(_tests_dir))

from conftest import (
    CaseSaver,
    MODEL_PATH,
    REF_AUDIO_PATH,
    INPUT_DIR,
    get_cases,
    load_case,
    assert_expected,
)

from core.schemas import (
    DuplexConfig,
    DuplexOfflineInput,
    DuplexOfflineOutput,
    DuplexChunkResult,
)
from core.processors import UnifiedProcessor, DuplexView


# =============================================================================
# Fixture: å…±äº«çš„ Processor å®ä¾‹
# =============================================================================

@pytest.fixture(scope="module")
def processor():
    """åˆ›å»ºå…±äº«çš„ DuplexView å®ä¾‹"""
    from conftest import PT_PATH
    print(f"\n[Setup] åŠ è½½ Duplex æ¨¡å‹: {MODEL_PATH}")
    print(f"[Setup] é¢å¤–æƒé‡: {PT_PATH}")
    unified = UnifiedProcessor(model_path=MODEL_PATH, pt_path=PT_PATH)
    duplex_view = unified.set_duplex_mode()
    yield duplex_view
    print("\n[Teardown] é‡Šæ”¾æ¨¡å‹")
    del unified
    if torch.cuda.is_available():
        torch.cuda.empty_cache()


# =============================================================================
# æ•°æ®æ„é€ è¾…åŠ©å‡½æ•°
# =============================================================================

def build_duplex_input(case_data: dict, saver: CaseSaver) -> DuplexOfflineInput:
    """ä» case JSON æ„é€ æ ‡å‡† DuplexOfflineInput
    
    æ”¯æŒçš„æ„é€ æ¨¡å¼ï¼š
    1. åŸºç¡€æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨ user_audio_path
    2. å›¾åƒè¿‡æ¸¡æ¨¡å¼ï¼šæ ¹æ® total_duration_s å’Œ image_transition_at_s æ„é€ 
    """
    input_data = case_data["input"]
    
    # å¤åˆ¶å‚è€ƒéŸ³é¢‘
    saver.copy_input_file(Path(input_data["ref_audio_path"]), "ref_audio.wav")
    
    # å¤„ç†ç”¨æˆ·éŸ³é¢‘
    if "total_duration_s" in input_data:
        # å›¾åƒè¿‡æ¸¡æ¨¡å¼ï¼šéœ€è¦æ„é€ æŒ‡å®šæ—¶é•¿çš„éŸ³é¢‘
        user_audio_path = _build_extended_audio(input_data, saver)
    else:
        # åŸºç¡€æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨
        user_audio_path = input_data["user_audio_path"]
        saver.copy_input_file(Path(user_audio_path), "user_audio.wav")
    
    # å¤„ç†å›¾åƒåˆ—è¡¨
    image_paths = None
    if "image_paths" in input_data:
        # ç›´æ¥æŒ‡å®šå›¾åƒåˆ—è¡¨
        image_paths = input_data["image_paths"]
        for i, p in enumerate(image_paths):
            src = Path(p)
            if src.exists():
                saver.copy_input_file(src, f"image_{i}.png")
    elif "image_transition_at_s" in input_data:
        # å›¾åƒè¿‡æ¸¡æ¨¡å¼ï¼šæ„é€ é»‘å±â†’çœŸå®å›¾åƒçš„åˆ—è¡¨
        image_paths = _build_transition_images(input_data, saver)
    
    # æ„é€ æ ‡å‡† DuplexOfflineInput
    return DuplexOfflineInput(
        system_prompt=input_data["system_prompt"],
        user_audio_path=str(user_audio_path),
        ref_audio_path=input_data["ref_audio_path"],
        image_paths=image_paths,
        config=DuplexConfig(**input_data.get("config", {})),
    )


def _build_extended_audio(input_data: dict, saver: CaseSaver) -> Path:
    """æ„é€ æŒ‡å®šæ—¶é•¿çš„ç”¨æˆ·éŸ³é¢‘ï¼ˆåŸéŸ³é¢‘ + é™éŸ³å¡«å……ï¼‰"""
    user_audio_path = Path(input_data["user_audio_path"])
    total_duration = input_data["total_duration_s"]
    
    # åŠ è½½åŸå§‹éŸ³é¢‘
    audio_start, _ = librosa.load(str(user_audio_path), sr=16000, mono=True)
    
    # æ„é€ å®Œæ•´éŸ³é¢‘
    total_samples = total_duration * 16000
    audio_full = np.zeros(total_samples, dtype=np.float32)
    audio_full[:len(audio_start)] = audio_start
    
    # ä¿å­˜
    output_path = saver.base_dir / "user_audio_extended.wav"
    sf.write(str(output_path), audio_full, 16000)
    saver.copy_input_file(user_audio_path, "user_audio_original.wav")
    
    return output_path


def _build_transition_images(input_data: dict, saver: CaseSaver) -> List[str]:
    """æ„é€ é»‘å±â†’çœŸå®å›¾åƒçš„è¿‡æ¸¡åˆ—è¡¨"""
    image_path = Path(input_data["image_path"])
    total_duration = input_data["total_duration_s"]
    transition_at = input_data["image_transition_at_s"]
    
    # åŠ è½½çœŸå®å›¾åƒ
    real_image = Image.open(image_path)
    saver.copy_input_file(image_path, "real_image.png")
    
    # åˆ›å»ºé»‘å±å›¾åƒ
    black_image = Image.new("RGB", real_image.size, (0, 0, 0))
    black_path = saver.base_dir / "black_image.png"
    black_image.save(black_path)
    
    # æ„é€ å›¾åƒåˆ—è¡¨
    image_paths = []
    for i in range(total_duration):
        if i < transition_at:
            image_paths.append(str(black_path))
        else:
            image_paths.append(str(image_path))
    
    return image_paths


# =============================================================================
# è¾…åŠ©å‡½æ•°
# =============================================================================

def run_duplex_offline(
    processor: DuplexView,
    task_input: DuplexOfflineInput,
    saver: CaseSaver,
) -> DuplexOfflineOutput:
    """æ‰§è¡ŒåŒå·¥ç¦»çº¿æ¨ç†å¹¶ä¿å­˜ chunks
    
    ä½¿ç”¨ processor.offline_inference() æ‰§è¡Œæ¨ç†ï¼Œ
    ç„¶åå°† chunks ä¿å­˜åˆ° CaseSaverã€‚
    """
    import base64
    
    # æ‰§è¡Œç¦»çº¿æ¨ç†
    result = processor.offline_inference(task_input)
    
    # æ”¶é›†æ‰€æœ‰éŸ³é¢‘
    all_audio = []
    
    # ä¿å­˜ chunksï¼ˆå¦‚æœæœ‰ï¼‰
    if result.chunks:
        for chunk in result.chunks:
            # è§£ç éŸ³é¢‘æ•°æ®
            audio_np = None
            if chunk.audio_data:
                audio_bytes = base64.b64decode(chunk.audio_data)
                audio_np = np.frombuffer(audio_bytes, dtype=np.float32)
                all_audio.append(audio_np)
            
            # ä¿å­˜ chunkï¼ˆåŒ…å«éŸ³é¢‘ï¼‰
            saver.save_chunk(
                chunk.chunk_idx, 
                chunk.model_dump(exclude={"audio_data"}),  # æ’é™¤ base64 æ•°æ®é¿å… JSON è¿‡å¤§
                audio_data=audio_np,
                sample_rate=24000
            )
    
    # åˆå¹¶å¹¶ä¿å­˜æ‰€æœ‰éŸ³é¢‘
    if all_audio:
        combined_audio = np.concatenate(all_audio)
        saver.save_output_audio(combined_audio, "combined.wav", sample_rate=24000)
    
    return result


# =============================================================================
# æ•°æ®æµ‹è¯•ï¼ˆData-Drivenï¼‰
# =============================================================================

class TestDuplexData:
    """Duplex æ•°æ®æµ‹è¯• - æ‰€æœ‰ case å…±ç”¨ä¸€ä¸ªæµ‹è¯•æ–¹æ³•"""
    
    @pytest.mark.parametrize("case_name", get_cases("duplex"))
    def test_duplex(self, processor, case_saver, case_name: str):
        """æ•°æ®é©±åŠ¨çš„ Duplex æµ‹è¯•"""
        saver: CaseSaver = case_saver(case_name, "duplex")
        
        # åŠ è½½ case æ•°æ®
        case = load_case("duplex", case_name, output_dir=saver.base_dir)
        print(f"\nğŸ“‹ {case['description']}")
        
        # æ„é€ æ ‡å‡†è¾“å…¥ï¼ˆç‰¹æ®Šæ„é€ é€»è¾‘åœ¨ build_duplex_input ä¸­å¤„ç†ï¼‰
        task_input = build_duplex_input(case, saver)
        
        # ä¿å­˜è¾“å…¥ï¼ˆæ ‡å‡† Schemaï¼‰
        saver.save_input(task_input)
        
        # æ‰§è¡Œæ¨ç†
        response = run_duplex_offline(processor, task_input, saver)
        
        # ä¿å­˜è¾“å‡ºï¼ˆæ ‡å‡† Schemaï¼‰
        saver.save_output(response)
        saver.finalize({"case_name": case_name, "description": case["description"]})
        
        # éªŒè¯
        assert_expected(response, case["expected"], output_dir=saver.base_dir)
        
        print(f"âœ… duplex_{case_name}: {response.full_text[:80]}{'...' if len(response.full_text) > 80 else ''}")


# =============================================================================
# çŠ¶æ€æµ‹è¯•ï¼ˆState Testsï¼‰
# =============================================================================

class TestDuplexState:
    """Duplex çŠ¶æ€æµ‹è¯• - éªŒè¯ prepare/prefill/generate æµç¨‹"""
    
    def test_prepare_prefill_generate_cycle(self, processor, case_saver):
        """æµ‹è¯•ï¼šprepare â†’ prefill â†’ generate å®Œæ•´æµç¨‹"""
        saver: CaseSaver = case_saver("state_prepare_prefill_generate", "duplex")
        
        # prepareï¼ˆä½¿ç”¨æ­£ç¡®çš„å‚æ•°åï¼‰
        processor.prepare(
            system_prompt_text="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚",
            ref_audio_path=str(REF_AUDIO_PATH),
        )
        
        # prefillï¼ˆé™éŸ³ chunkï¼Œä½¿ç”¨æ­£ç¡®çš„å‚æ•°åï¼‰
        silent_chunk = np.zeros(16000, dtype=np.float32)
        processor.prefill(audio_waveform=silent_chunk)
        
        # generateï¼ˆæ— å‚æ•°ï¼‰
        result = processor.generate()
        
        saver.save_output({
            "is_listen": result.is_listen,
            "text": result.text or "",
            "has_audio": result.audio_data is not None,
        })
        saver.finalize({"test": "prepare_prefill_generate_cycle"})
        
        print(f"âœ… prepare/prefill/generate æµç¨‹æµ‹è¯•å®Œæˆ")
        print(f"   is_listen: {result.is_listen}")
        print(f"   text: {(result.text or '')[:50]}")
    
    def test_offline_inference(self, processor, case_saver):
        """æµ‹è¯•ï¼šoffline_inference ä¾¿æ·æ–¹æ³•"""
        saver: CaseSaver = case_saver("state_offline_inference", "duplex")
        
        # ä½¿ç”¨ offline_inference
        task_input = DuplexOfflineInput(
            system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚",
            user_audio_path=str(INPUT_DIR / "user_audio" / "000_user_audio0.wav"),
            ref_audio_path=str(REF_AUDIO_PATH),
            config=DuplexConfig(force_listen_count=3),
        )
        
        saver.copy_input_file(REF_AUDIO_PATH, "ref_audio.wav")
        saver.save_input(task_input)
        
        response = processor.offline_inference(task_input)
        
        saver.save_output(response)
        saver.finalize({"test": "offline_inference"})
        
        assert response.success, f"offline_inference åº”è¯¥æˆåŠŸï¼Œä½†è¿”å›: {response.error}"
        print(f"âœ… offline_inference æµ‹è¯•å®Œæˆ")
        print(f"   text: {response.full_text[:80]}")
        print(f"   audio: {response.audio_duration_s:.2f}s")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
