<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>Duplex 模式 - MiniCPM-o 4.5 文档</title>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
<style>
* { margin:0; padding:0; box-sizing:border-box; }
:root {
  --sidebar-w: 260px;
  --bg: #fff; --bg-side: #f8f9fa; --bg-code: #f6f8fa;
  --c1: #24292f; --c2: #57606a;
  --border: #d0d7de; --accent: #0969da; --nav-active: #ddf4ff;
}
body { font-family: -apple-system,BlinkMacSystemFont,"Segoe UI","Noto Sans",Helvetica,Arial,sans-serif; color:var(--c1); line-height:1.6; background:var(--bg); }
.sidebar-toggle { position:fixed; top:12px; left:12px; z-index:1001; background:var(--bg-side); border:1px solid var(--border); border-radius:6px; padding:6px 10px; font-size:18px; cursor:pointer; display:none; }
.sidebar { position:fixed; top:0; left:0; width:var(--sidebar-w); height:100vh; overflow-y:auto; background:var(--bg-side); border-right:1px solid var(--border); padding:20px 0; z-index:1000; transition:transform .3s; }
.sidebar-header { padding:0 20px 16px; border-bottom:1px solid var(--border); margin-bottom:8px; }
.sidebar-header h2 { font-size:16px; font-weight:600; }
.sidebar-subtitle { font-size:12px; color:var(--c2); }

.nav-list { list-style:none; padding:0 8px; }
.nav-list > li > a { display:block; padding:7px 12px; color:var(--c2); text-decoration:none; font-size:14px; border-radius:6px; transition:background .15s,color .15s; }
.nav-list > li > a:hover { background:#e8e8e8; color:var(--c1); }
.nav-list > li > a.active { background:var(--nav-active); color:var(--accent); font-weight:600; }

.nav-group { margin-top:4px; }
.nav-group-header { display:flex; align-items:center; gap:6px; padding:8px 12px; color:var(--c1); font-size:12px; font-weight:700; text-transform:uppercase; letter-spacing:.04em; cursor:pointer; border-radius:6px; user-select:none; transition:background .15s; }
.nav-group-header:hover { background:#eaeef2; }
.nav-group-header::before { content:""; display:inline-block; width:0; height:0; border-left:5px solid var(--c2); border-top:3.5px solid transparent; border-bottom:3.5px solid transparent; transition:transform .2s; transform:rotate(90deg); flex-shrink:0; }
.nav-group.collapsed .nav-group-header::before { transform:rotate(0); }
.nav-group-children { list-style:none; margin:0 0 4px 19px; padding:3px 0 3px 13px; border-left:2px solid #e1e4e8; overflow:hidden; max-height:500px; transition:max-height .25s ease,opacity .2s ease,padding .2s ease; opacity:1; }
.nav-group.collapsed .nav-group-children { max-height:0; opacity:0; padding:0 0 0 13px; }
.nav-group-children li a { display:block; padding:4px 10px; font-size:13px; color:var(--c2); text-decoration:none; border-radius:4px; transition:background .15s,color .15s; }
.nav-group-children li a:hover { background:#e8e8e8; color:var(--c1); }
.nav-group-children li a.active { background:var(--nav-active); color:var(--accent); font-weight:600; }

.content { margin-left:var(--sidebar-w); max-width:900px; padding:40px 48px; }
article h1 { font-size:28px; font-weight:600; padding-bottom:10px; border-bottom:1px solid var(--border); margin-bottom:20px; }
article h2 { font-size:22px; font-weight:600; margin-top:32px; margin-bottom:12px; padding-bottom:6px; border-bottom:1px solid #eaecef; }
article h3 { font-size:18px; font-weight:600; margin-top:24px; margin-bottom:10px; }
article h4 { font-size:15px; font-weight:600; margin-top:20px; margin-bottom:8px; }
article p { margin-bottom:14px; }
article ul,article ol { margin-bottom:14px; padding-left:24px; }
article li { margin-bottom:4px; }
article a { color:var(--accent); text-decoration:none; }
article a:hover { text-decoration:underline; }
article code { background:var(--bg-code); padding:2px 6px; border-radius:4px; font-size:13px; font-family:"SFMono-Regular",Consolas,"Liberation Mono",Menlo,monospace; }
article pre { background:var(--bg-code); border:1px solid var(--border); border-radius:6px; padding:16px; overflow-x:auto; margin-bottom:16px; line-height:1.5; }
article pre code { background:none; padding:0; font-size:13px; }
article table { width:100%; border-collapse:collapse; margin-bottom:16px; font-size:14px; }
article th,article td { border:1px solid var(--border); padding:8px 12px; text-align:left; }
article th { background:var(--bg-code); font-weight:600; }
article tr:nth-child(even) { background:#f8f9fa; }
article hr { border:none; border-top:1px solid var(--border); margin:28px 0; }
article blockquote { border-left:4px solid var(--accent); padding:8px 16px; margin:0 0 16px; color:var(--c2); background:#f8f9fa; border-radius:0 6px 6px 0; }
article .mermaid { text-align:center; margin:20px 0; }
footer { margin-top:60px; padding-top:16px; border-top:1px solid var(--border); color:var(--c2); font-size:13px; }
@media(max-width:768px) {
  .sidebar { transform:translateX(-100%); }
  .sidebar.open { transform:translateX(0); box-shadow:2px 0 8px rgba(0,0,0,.15); }
  .sidebar-toggle { display:block; }
  .content { margin-left:0; padding:50px 20px 40px; }
  .content.shifted { margin-left:var(--sidebar-w); }
}
</style>
</head>
<body>
<button class="sidebar-toggle" onclick="toggleSidebar()" aria-label="Toggle sidebar">&#9776;</button>
<nav class="sidebar" id="sidebar">
  <div class="sidebar-header">
    <h2>MiniCPM-o 4.5</h2>
    <span class="sidebar-subtitle">项目文档</span>
  </div>
  <ul class="nav-list">
    <li><a href="../index.html">项目概述</a></li>
    <li class="nav-group">
      <span class="nav-group-header">系统架构</span>
      <ul class="nav-group-children">
        <li><a href="../architecture/index.html">架构概述</a></li>
        <li><a href="../architecture/streaming.html">Streaming 模式</a></li>
        <li><a href="../architecture/duplex.html" class="active">Duplex 模式</a></li>
        <li><a href="../architecture/internals.html">内部机制</a></li>
      </ul>
    </li>
    <li><a href="../gateway.html">Gateway 模块</a></li>
    <li><a href="../worker.html">Worker 模块</a></li>
    <li><a href="../schema.html">Schema</a></li>
    <li><a href="../model.html">模型模块</a></li>
    <li><a href="../compile.html">torch.compile</a></li>
    <li class="nav-group">
      <span class="nav-group-header">前端模块</span>
      <ul class="nav-group-children">
        <li><a href="../frontend/index.html">前端概述</a></li>
        <li><a href="../frontend/pages.html">页面与路由</a></li>
        <li><a href="../frontend/audio.html">音频处理</a></li>
        <li><a href="../frontend/duplex-session.html">双工会话</a></li>
        <li><a href="../frontend/components.html">UI 组件</a></li>
      </ul>
    </li>
    <li><a href="../api.html">API 参考</a></li>
    <li><a href="../deployment.html">配置与部署</a></li>
  </ul>
</nav>
<main class="content" id="content">
  <article><h1 id="duplex">Duplex 模式详解</h1>
<p>Duplex 接口（<code>/ws/duplex/{session_id}</code>）支持两种全双工交互模式：</p>
<ul>
<li><strong>Omnimodal Full-Duplex</strong>：每秒发送 <code>audio_chunk</code> + <code>video_frame</code>，模型同时处理视觉和语音</li>
<li><strong>Audio Full-Duplex</strong>：每秒仅发送 <code>audio_chunk</code>，无视觉输入</li>
</ul>
<p>两者共享相同的 prefill-generate unit 循环，区别仅在于是否传入视频帧。</p>
<h2 id="_1">基础概念</h2>
<p>Duplex（全双工）模式实现了类似电话的实时对话体验：用户说话的同时，模型可以随时开口回应，无需等待用户说完。</p>
<p>与 Streaming 模式的关键区别：</p>
<table>
<thead>
<tr>
<th></th>
<th>Streaming 模式</th>
<th>Duplex 模式</th>
</tr>
</thead>
<tbody>
<tr>
<td>交互方式</td>
<td>轮次式（用户说完 → 模型回答）</td>
<td>实时全双工（同时收听和回应）</td>
</tr>
<tr>
<td>输入处理</td>
<td>一次性 prefill 完整消息</td>
<td>每秒流式 prefill 音频/视频</td>
</tr>
<tr>
<td>Worker 占用</td>
<td>仅推理期间占用，完成即释放</td>
<td>整个会话期间独占</td>
</tr>
<tr>
<td>适用场景</td>
<td>文本/多模态问答</td>
<td>语音/视频实时对话</td>
</tr>
</tbody>
</table>
<h2 id="unit">每秒一次的 Unit 循环</h2>
<p>Duplex 的核心是一个 <strong>每秒执行一次</strong> 的 prefill-generate 循环，每次循环称为一个 "unit"：</p>
<pre class="mermaid">
sequenceDiagram
    participant C as 客户端
    participant W as Worker

    C->>W: prepare (系统提示词 + ref_audio)
    W->>W: 初始化: reset → prefill system prompt + 音频参考

    loop 每秒一个 Unit
        C->>W: audio_chunk (~1s) + video_frame
        W->>W: streaming_prefill()
        Note over W: 1. feed ⟨unit⟩ token<br/>2. 编码图像 → feed 视觉 embedding<br/>3. 编码音频 → feed 音频 embedding<br/>4. 产生 pending_logits
        W->>W: streaming_generate()
        Note over W: 基于 pending_logits 解码<br/>输出 ⟨listen⟩ → 继续聆听<br/>输出文本 token → 说话
        alt 模型决定说话
            W-->>C: text + audio_data
        else 模型决定聆听
            W-->>C: is_listen=true
        end
    end
</pre>

<p><code>streaming_prefill()</code> 每秒接收一段音频（和可选的视频帧），编码后 feed 进 LLM 的 KV Cache：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># MiniCPMO45/modeling_minicpmo_unified.py — DuplexCapability.streaming_prefill()</span>
<span class="c1"># 每秒调用一次，根据输入确定模式: AUDIO / VISION / OMNI</span>

<span class="c1"># Step 1: feed &lt;unit&gt; token（标记新 unit 开始）</span>
<span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">feed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">embed_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unit_token_id</span><span class="p">))</span>

<span class="c1"># Step 2: 编码图像 → feed 视觉 embedding（如有视频帧）</span>
<span class="n">vision_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_vision_embedding</span><span class="p">(</span><span class="n">processed_frames</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">feed</span><span class="p">(</span><span class="n">vision_embed</span><span class="p">)</span>

<span class="c1"># Step 3: 编码音频 → feed 音频 embedding</span>
<span class="n">audio_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_audio_embedding</span><span class="p">(</span><span class="n">processed_audio</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">feed</span><span class="p">(</span><span class="n">audio_embed</span><span class="p">)</span>
<span class="c1"># → 产生 pending_logits，供 generate 使用</span>
</code></pre></div>

<p><code>streaming_generate()</code> 基于 <code>pending_logits</code> 解码，模型自主决定是"聆听"还是"说话"：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># MiniCPMO45/modeling_minicpmo_unified.py — DuplexCapability.streaming_generate()</span>
<span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pending_logits</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_speak_tokens_per_chunk</span><span class="p">):</span>
    <span class="n">last_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">decode_mode</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>

    <span class="n">is_listen</span> <span class="o">=</span> <span class="n">last_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">listen_token_id</span>
    <span class="k">if</span> <span class="n">last_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">chunk_terminator_token_ids</span><span class="p">:</span>
        <span class="k">break</span>  <span class="c1"># 本 chunk 结束（listen / chunk_eos / turn_eos）</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">last_id</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>  <span class="c1"># 记录说话 token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speak_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">feed</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>  <span class="c1"># feed token, 获取下一步 logits</span>
</code></pre></div>

<h2 id="gateway">完整流程（含排队 + Gateway 代理）</h2>
<pre class="mermaid">
sequenceDiagram
    participant C as 客户端
    participant G as Gateway
    participant Q as 队列
    participant W as Worker

    C->>G: WS /ws/duplex/{session_id}
    G->>Q: enqueue("omni_duplex" / "audio_duplex")
    Q->>W: 分配 Worker（独占）
    C->>G: prepare (系统提示词 + 配置)
    G->>W: duplex_prepare()
    loop 全双工循环（每秒一次）
        C->>G: audio_chunk (+ video_frame)
        G->>W: duplex_prefill(audio, frames)
        W->>W: duplex_generate()
        alt 模型决定说话
            W-->>G: result (text + audio_data)
            G-->>C: 转发 result
        else 模型决定聆听
            W-->>G: result (is_listen=true)
        end
    end
    C->>G: stop
    G->>W: duplex_cleanup()
    G->>Q: release_worker()
</pre>

<h2 id="omnimodal-vs-audio">Omnimodal vs Audio 模式</h2>
<p>Gateway 在入队时通过 <code>task_type</code> 区分两种模式：</p>
<table>
<thead>
<tr>
<th></th>
<th>Omnimodal Full-Duplex</th>
<th>Audio Full-Duplex</th>
</tr>
</thead>
<tbody>
<tr>
<td>入队 task_type</td>
<td><code>omni_duplex</code></td>
<td><code>audio_duplex</code></td>
</tr>
<tr>
<td>前端页面</td>
<td><code>omni.html</code></td>
<td><code>audio_duplex.html</code></td>
</tr>
<tr>
<td>每秒发送</td>
<td><code>audio_chunk</code> + <code>video_frame</code></td>
<td><code>audio_chunk</code></td>
</tr>
<tr>
<td><code>streaming_prefill()</code> 模式</td>
<td>OMNI（音频 + 视觉）</td>
<td>AUDIO（仅音频）</td>
</tr>
<tr>
<td>视觉编码</td>
<td>SigLIP → Resampler → feed</td>
<td>跳过</td>
</tr>
</tbody>
</table>
<p>两种模式在 Worker 侧共享完全相同的代码路径，<code>DuplexCapability.streaming_prefill()</code> 根据是否传入 <code>frame_list</code> 自动选择模式（AUDIO / VISION / OMNI）。</p>
<h2 id="worker">Worker 侧处理细节</h2>
<p>Duplex 是最复杂的独占模式，Worker 在整个会话期间被独占。</p>
<h3 id="prepare">prepare 阶段</h3>
<ol>
<li>设置状态 → <code>DUPLEX_ACTIVE</code>（独占 Worker）</li>
<li>解码 LLM ref_audio 和 TTS ref_audio（两者可以不同）：</li>
<li>LLM ref_audio → 嵌入 system prompt</li>
<li>TTS ref_audio → 初始化 vocoder</li>
<li><code>duplex_prepare(system_prompt, ref_audio, tts_audio)</code> 初始化双工会话</li>
<li>初始化 <code>DuplexSessionRecorder</code>（可选）</li>
<li>发送 <code>prepared</code></li>
</ol>
<h3 id="_2">全双工循环</h3>
<p>每轮循环处理一个音频 chunk（约 1 秒）：</p>
<ol>
<li>解码 <code>audio_base64</code> → float32 音频波形（16kHz）</li>
<li>解码 <code>frame_base64_list</code> → PIL Image 列表（仅 Omni 模式）</li>
<li>等待上一轮 finalize 完成（<code>asyncio.Event</code> 栅栏）</li>
<li>在线程中执行：</li>
<li><code>duplex_prefill(audio, frames)</code> — 预填充音频 + 视频</li>
<li><code>duplex_generate(force_listen)</code> — 模型决定 listen 或 speak</li>
<li>发送 <code>result</code>（含 <code>is_listen</code>, <code>text</code>, <code>audio_data</code>, 性能指标, <code>kv_cache_length</code>）</li>
<li><strong>Deferred Finalize</strong>（默认开启）：</li>
<li>先发送结果给客户端（overlap 网络传输）</li>
<li>异步执行 <code>duplex_finalize()</code>（约 37ms，feed 终止符 + 滑窗维护）</li>
<li>通过 <code>asyncio.Event</code> 栅栏保证在下轮 prefill 前完成</li>
<li>实测：LISTEN wall_clock 降低约 30ms，SPEAK 降低约 50ms</li>
</ol>
<h3 id="_3">暂停与恢复</h3>
<ul>
<li><code>pause</code> → <code>DUPLEX_PAUSED</code> + 启动超时看门狗</li>
<li><code>resume</code> → <code>DUPLEX_ACTIVE</code> + 取消看门狗</li>
<li>超时（默认 60s）→ 自动释放 Worker，通知客户端</li>
</ul>
<h3 id="_4">停止与资源清理</h3>
<ul>
<li><code>stop</code> → <code>duplex_stop()</code></li>
<li><code>finally</code> 块（无论正常/异常结束）：</li>
<li><code>duplex_stop()</code> 停止生成</li>
<li><code>duplex_cleanup()</code> 释放 GPU 资源：<ul>
<li>释放 KV Cache、TTS caches 等</li>
<li><code>gc.collect()</code> + <code>torch.cuda.empty_cache()</code></li>
<li>释放约 1.5GB 显存（诊断数据：stop 后泄漏 ~1,591 MB → cleanup 后残留 ~48 MB）</li>
</ul>
</li>
<li>状态恢复 → <code>IDLE</code></li>
</ul></article>
  <footer><p>MiniCPM-o 4.5 PyTorch Simple Demo &mdash; 由 build_docs.py 自动生成</p></footer>
</main>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/json.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>
<script type="module">
import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
mermaid.initialize({startOnLoad:true,theme:'default',securityLevel:'loose'});
</script>
<script>
hljs.highlightAll();
function toggleSidebar(){document.getElementById('sidebar').classList.toggle('open');document.getElementById('content').classList.toggle('shifted');}
document.querySelectorAll('.nav-group-header').forEach(function(h){h.addEventListener('click',function(){this.parentElement.classList.toggle('collapsed');});});
document.addEventListener('click',function(e){var s=document.getElementById('sidebar'),t=document.querySelector('.sidebar-toggle');if(window.innerWidth<=768&&s.classList.contains('open')&&!s.contains(e.target)&&!t.contains(e.target)){s.classList.remove('open');document.getElementById('content').classList.remove('shifted');}});
</script>
</body>
</html>
